{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EsmaeilNarimissa/Dialectal-Retrieval-Bias/blob/main/aave_dataset_generation_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8644fe41",
      "metadata": {
        "id": "8644fe41"
      },
      "source": [
        "# **Phase 1: AAVE/SAE Dataset Generation**\n",
        "\n",
        "This notebook implements a complete pipeline for generating a hybrid dataset containing both Standard American English (SAE) and African American Vernacular English (AAVE) queries for research on dialectal bias in RAG systems.\n",
        "\n",
        "**Overview**\n",
        "\n",
        "The notebook is structured in three main phases:\n",
        "1. **Setup and Configuration**: Import libraries, load API keys, and define constants\n",
        "2. **Data Sourcing**: Load and filter the SQuAD dataset for suitable queries\n",
        "3. **Synthetic Generation**: Use LLM API calls to convert SAE queries to AAVE variants\n",
        "\n",
        "**Requirements**\n",
        "\n",
        "Before running this notebook, ensure you have:\n",
        "- OpenAI API key set as environment variable `OPENAI_API_KEY`\n",
        "- Sufficient API credits for the generation process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d18a7ddb",
      "metadata": {
        "id": "d18a7ddb"
      },
      "source": [
        "## Step 1: Setup and Configuration\n",
        "\n",
        "Setting up the environment with necessary libraries, API keys, and configuration constants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e310003",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e310003",
        "outputId": "bd7473dd-d625-4302-f66b-80d4faa35c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Packages installed successfully\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q datasets openai tqdm pandas numpy openai\n",
        "\n",
        "print(\"Packages installed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac9e8c14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac9e8c14",
        "outputId": "4b1e5a30-3827-48e7-e4eb-763a45935b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully\n",
            "OpenAI API key loaded successfully from Colab secrets\n",
            "OpenAI Client initialized.\n",
            "\n",
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "OpenAI SDK version: 1.108.0\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import random\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "import warnings\n",
        "import sys # Added for Python version check\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "\n",
        "# Load API keys and configuration\n",
        "# Use Google Colab's user data secrets to securely store the API key\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    print(\"ERROR: OPENAI_API_KEY not found in Colab secrets!\")\n",
        "    print(\"Please set your OpenAI API key in the Colab Secrets tab (icon on the left).\")\n",
        "else:\n",
        "    print(\"OpenAI API key loaded successfully from Colab secrets\")\n",
        "\n",
        "# Initialize OpenAI client with the modern SDK\n",
        "from openai import OpenAI, __version__ as openai_version # Import necessary classes/versions\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "print(\"OpenAI Client initialized.\")\n",
        "\n",
        "# Verify OpenAI SDK and Python versions\n",
        "print(\"\\nPython:\", sys.version) # Use sys for Python version\n",
        "try:\n",
        "    print(\"OpenAI SDK version:\", openai_version) # Use imported openai_version\n",
        "except Exception as e:\n",
        "    print(\"Could not read OpenAI SDK version:\", repr(e))\n",
        "\n",
        "# Legacy version attribute fallback - for older installs if needed\n",
        "# print(\"openai version (legacy attr):\", getattr(openai, \"__version__\", \"N/A\")) # This might not be needed with modern SDK import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = \"gpt-4.1-mini\"  # change if your org uses different names\n",
        "print(\"Testing model:\", test_model)\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=test_model,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Say 'hello'?\"}],\n",
        "    max_completion_tokens=10,\n",
        ")\n",
        "print(\"Response:\", repr(resp.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW4iXKtP_ot6",
        "outputId": "be7708e1-65ee-49ef-a29e-936fc315793d"
      },
      "id": "jW4iXKtP_ot6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing model: gpt-4.1-mini\n",
            "Response: 'Hello! How can I assist you today?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat Completions Model Probe\n",
        "Test a shortlist of chat.completions models, log success/failure and a sample reply.\n",
        "\n",
        "**OpenAI Pricing per 1M tokens (27/Sep/25):**\n",
        "\n",
        "| Model             | Input (USD) | Cached input (USD) | Output (USD) |\n",
        "|-------------------|-----------|------------------|------------|\n",
        "| gpt-5             | 1.25      | 0.125            | 10.00      |\n",
        "| gpt-5-mini        | 0.25      | 0.025            | 2.00       |\n",
        "| gpt-5-nano        | 0.05      | 0.005            | 0.40       |\n",
        "| gpt-5-chat-latest | 1.25      | 0.125            | 10.00      |\n",
        "| gpt-5-codex       | 1.25      | 0.125            | 10.00      |\n",
        "| gpt-4.1           | 2.00      | 0.50             | 8.00       |\n",
        "| gpt-4.1-mini      | 0.40      | 0.10             | 1.60       |\n",
        "| gpt-4.1-nano      | 0.10      | 0.025            | 0.40       |\n",
        "| gpt-4o            | 2.50      | 1.25             | 10.00      |\n"
      ],
      "metadata": {
        "id": "W5OqpEXfkoe_"
      },
      "id": "W5OqpEXfkoe_"
    },
    {
      "cell_type": "code",
      "source": [
        "CANDIDATE_MODELS = [\n",
        "    \"gpt-5\",         # top-tier quality\n",
        "    \"gpt-4o\",        # strong multimodal family, robust chat-completions\n",
        "    \"gpt-4.1\",       # strong reasoning, broadly supported\n",
        "    \"gpt-4o-mini\",   # economical, good quality\n",
        "    \"gpt-4.1-mini\",  # economical, known to work (we verified)\n",
        "    \"gpt-5-mini\",    # cheap, may have endpoint constraints in some orgs\n",
        "]\n",
        "\n",
        "def probe_chat_models(models: list[str], max_completion_tokens: int = 8) -> dict:\n",
        "    \"\"\"\n",
        "    Try a minimal chat completion on each model and report status and sample text.\n",
        "    Returns a dict: {model: {\"ok\": bool, \"error\": str|None, \"sample\": str|None}}\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    for m in models:\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=m,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Reply with one short word only.\"},\n",
        "                    {\"role\": \"user\", \"content\": \"Hello?\"},\n",
        "                ],\n",
        "                max_completion_tokens=max_completion_tokens,\n",
        "            )\n",
        "            content = (resp.choices[0].message.content or \"\").strip()\n",
        "            ok = bool(content)\n",
        "            results[m] = {\"ok\": ok, \"error\": None if ok else \"Empty content\", \"sample\": content if ok else None}\n",
        "            print(f\"[OK] {m}: {repr(content)}\" if ok else f\"[EMPTY] {m}\")\n",
        "        except Exception as e:\n",
        "            # Capture concise error\n",
        "            results[m] = {\"ok\": False, \"error\": str(e), \"sample\": None}\n",
        "            print(f\"[ERR] {m}: {e}\")\n",
        "    return results\n",
        "\n",
        "print(\"Probing chat-completions models...\")\n",
        "model_probe_results = probe_chat_models(CANDIDATE_MODELS)\n",
        "print(\"\\nSummary:\")\n",
        "for m, r in model_probe_results.items():\n",
        "    status = \"OK\" if r[\"ok\"] else \"FAIL\"\n",
        "    sample = f\" sample={repr(r['sample'])}\" if r[\"sample\"] else \"\"\n",
        "    err = f\" error={r['error']}\" if r[\"error\"] else \"\"\n",
        "    print(f\"- {m}: {status}{sample}{err}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bgg-GvGyBc1I",
        "outputId": "c7a92818-ed98-4377-8d6a-baea8efe01fa"
      },
      "id": "Bgg-GvGyBc1I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probing chat-completions models...\n",
            "[EMPTY] gpt-5\n",
            "[OK] gpt-4o: 'Hi!'\n",
            "[OK] gpt-4.1: 'Hi!'\n",
            "[OK] gpt-4o-mini: 'Hi!'\n",
            "[OK] gpt-4.1-mini: 'Hi!'\n",
            "[EMPTY] gpt-5-mini\n",
            "\n",
            "Summary:\n",
            "- gpt-5: FAIL error=Empty content\n",
            "- gpt-4o: OK sample='Hi!'\n",
            "- gpt-4.1: OK sample='Hi!'\n",
            "- gpt-4o-mini: OK sample='Hi!'\n",
            "- gpt-4.1-mini: OK sample='Hi!'\n",
            "- gpt-5-mini: FAIL error=Empty content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation:\n",
        "\n",
        "- Primary: gpt-4.1-mini — best price/quality balance; it works.\n",
        "- Alternative higher quality: gpt-4.1 or gpt-4o — more expensive, potentially slightly better linguistic nuance.\n",
        "- Budget option: gpt-4o-mini — cheap and capable; if results look fine on a small sample, you can scale with it."
      ],
      "metadata": {
        "id": "abTGWJqOCFMY"
      },
      "id": "abTGWJqOCFMY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c63bce8",
      "metadata": {
        "id": "0c63bce8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41665f4a-0d15-4b6c-8b5f-335607784216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded:\n",
            "  dataset_name: squad\n",
            "  dataset_split: train\n",
            "  sample_size: 200\n",
            "  min_query_length: 10\n",
            "  max_query_length: 200\n",
            "  output_file: aave_poc_dataset_20250927-193921.json\n",
            "  model_name: gpt-4.1-mini\n",
            "  max_retries: 3\n",
            "  retry_delay: 1\n",
            "  batch_size: 10\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo  # Python 3.9+\n",
        "\n",
        "# Change to your local tz name if different\n",
        "LOCAL_TZ = ZoneInfo(\"Australia/Sydney\")\n",
        "RUN_ID = datetime.now(LOCAL_TZ).strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Configuration constants\n",
        "CONFIG = {\n",
        "    # Dataset configuration\n",
        "    'dataset_name': 'squad',\n",
        "    'dataset_split': 'train',\n",
        "    'sample_size': 200,  # Number of queries to process\n",
        "    'min_query_length': 10,\n",
        "    'max_query_length': 200,  # A typical question is between 30-80 characters!\n",
        "\n",
        "    # Output configuration\n",
        "    'output_file': f\"aave_poc_dataset_{RUN_ID}.json\", # Using the dynamic RUN_ID\n",
        "    # Note: BASE_OUTPUT was removed as it's not defined or used consistently\n",
        "\n",
        "    # Model configuration\n",
        "    'model_name': 'gpt-4.1-mini', # or \"gpt-4.1\" / \"gpt-4o\" / \"gpt-4o-mini\"\n",
        "\n",
        "    # API call configuration\n",
        "    'max_retries': 3,\n",
        "    'retry_delay': 1,  # seconds\n",
        "\n",
        "    # Progress tracking configuration\n",
        "    'batch_size': 10,  # Progress tracking in the original notebook\n",
        "}\n",
        "\n",
        "print(\"Configuration loaded:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a52cf134",
      "metadata": {
        "id": "a52cf134"
      },
      "source": [
        "## Step 2: Data Sourcing\n",
        "\n",
        "Loading the SQuAD dataset and filtering suitable queries for AAVE conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2e5988",
      "metadata": {
        "id": "1b2e5988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "406ad618dd464122b8a55d5fd8a63224",
            "33d9e9b389664975a0259d397312b7aa",
            "d752662294a74510b2361f25e7e0fae1",
            "868f624d95d44fe29a452ffb78db63a6",
            "9238fb659a894bc68868b4a8990b5574",
            "1d1bb06f23cd41b4a14f0cd8345a61b6",
            "2848a313493d49abb0c8d637cfba19c4",
            "2c2529c57cdf4065ac43bef725b8157b",
            "5cea234d4165472e9bc52bcb1374a185",
            "5eb602f3f4fd43bfba9bc8827013493c",
            "27d7fb99ba20445590eba7f98308aded",
            "b3e14b90209a4c888d43355b4b550d25",
            "df2ce6f7b2514033a2ef300e0353d8cf",
            "d096adc2cce54a5891a27dec18ccec89",
            "12a61c7e8f9a401db19cc157be06b493",
            "60e6057855d84ce8885955ca9d2cb566",
            "e7a36e1fa2e74cee939c02a3e75e9ef7",
            "73bbbe23b97d486cbb130ce1a7c1000e",
            "6b1c032d15c1498b928417546cbb4aac",
            "f2a8de14f33b4dcda799060df8a77902",
            "db75b6a3c5e548bda2a6131f82399c8f",
            "fef9cec418034a7982224a15d9ebc009",
            "d16d10a47a5b470baa16bdd80d64601c",
            "74241bf4ee3148d59b19fc477d0bb106",
            "7a960598971b4e43b7f5cbc101d1891e",
            "794f65be8eb84e209fc972063ffdc358",
            "11974667210247aab1fac570823e660f",
            "c106e7f66ffd45fa9a656791a5b51f1f",
            "37f86d1bccb945ba80b18f02ccb2fb51",
            "d31cf6b3c8f244d2bc2e880706703602",
            "710b14342f8b47a682a194f2527e36de",
            "4df38dd7f63645448b75bb7e85781379",
            "29df4a74cd944053ba3b871961712ea0",
            "cc42462b023d4dd7bc00b58d316002a3",
            "456a3912900143e988227514bc5c6932",
            "c1c30fef6ea44d95b5450520682d79af",
            "3641c0b2734f4e43bf918ead4f3c385a",
            "2b07b78180e54226a61c16b7ddbabe70",
            "2763b7728d36406987c68962dcd9686a",
            "9f0cc9e429c04f40bdccd28f0d2ef00d",
            "db72e37566554bafb80090e9e6e6274c",
            "39e0e420cfa34fd489152b3c4b5d2eed",
            "5db734959f6b4d448014512309dbea1f",
            "91a81c215ba14808a4a740dd6fed9d2a",
            "0b89974a4d35477ba49c28a6703cc5ef",
            "2e4be5da5f884723b2345fc17cb435bf",
            "c60b9c9ef2d54312962d83f8adebf5da",
            "30f81b01e2b140839105cce94c9c32d1",
            "10d0c7420398440c849228a5966475d5",
            "1c9d6eaea9d1439da234da8d8e0536ff",
            "9d7326e88a2549dcab0b31f6e322fb9c",
            "c32b0bbe44c7475185068f5aff26df6d",
            "4d619e18c402443ba2d8ac5d5e0306a1",
            "6fc6652fc41142e5af9849d1d30b63cf",
            "4f822d39afbd41a8b1a6f335f623f7aa"
          ]
        },
        "outputId": "234cc149-b91d-4680-a261-accf4cce8783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SQuAD dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "406ad618dd464122b8a55d5fd8a63224"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3e14b90209a4c888d43355b4b550d25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/validation-00000-of-00001.par(…):   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d16d10a47a5b470baa16bdd80d64601c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc42462b023d4dd7bc00b58d316002a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b89974a4d35477ba49c28a6703cc5ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully: 87599 examples\n"
          ]
        }
      ],
      "source": [
        "# Load SQuAD dataset\n",
        "print(\"Loading SQuAD dataset...\")\n",
        "try:\n",
        "    dataset = load_dataset(CONFIG['dataset_name'], split=CONFIG['dataset_split'])\n",
        "    print(f\"Dataset loaded successfully: {len(dataset)} examples\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baaa36a1",
      "metadata": {
        "id": "baaa36a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46933674-cfef-497f-f1b7-6f0869a413ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting and filtering queries...\n",
            "Extracted 86229 suitable (idx, question) pairs\n",
            "Randomly sampled 200 pairs for processing\n",
            "\n",
            " Sample queries:\n",
            "  1. (Index: 85143) Who overshadowed House Speaker Dennis Hastert?\n",
            "  2. (Index: 14741) Who released Mosaic?\n",
            "  3. (Index: 3320) How deep was the focus of the earthquake?\n",
            "  4. (Index: 36349) A person is not a member of a racial minority if ancetry does not what?\n",
            "  5. (Index: 32363) When was the first 3.7 cm FlaK 18 introduced?\n"
          ]
        }
      ],
      "source": [
        "# Extract and filter queries\n",
        "def extract_queries(dataset) -> List[Tuple[int, str]]:\n",
        "    \"\"\"Extract representative, high-quality SQuAD questions and their indices for AAVE conversion.\"\"\"\n",
        "    queries = []\n",
        "    seen = set()\n",
        "\n",
        "    for i, ex in enumerate(dataset):\n",
        "        q = ex[\"question\"].strip()\n",
        "        q_lower = q.lower()\n",
        "\n",
        "        # Quality checks\n",
        "        if not (CONFIG[\"min_query_length\"] <= len(q) <= CONFIG[\"max_query_length\"]):\n",
        "            continue\n",
        "        if not q.endswith(\"?\"):\n",
        "            continue\n",
        "        if len(q.split()) < 3:\n",
        "            continue\n",
        "\n",
        "        # Deduplicate (case-insensitive)\n",
        "        if q_lower in seen:\n",
        "            continue\n",
        "        seen.add(q_lower)\n",
        "\n",
        "        queries.append((i, q)) # Store as (index, question) tuple\n",
        "\n",
        "    return queries\n",
        "\n",
        "print(\"Extracting and filtering queries...\")\n",
        "all_queries = extract_queries(dataset)\n",
        "print(f\"Extracted {len(all_queries)} suitable (idx, question) pairs\")\n",
        "\n",
        "# Sample queries for processing\n",
        "if len(all_queries) > CONFIG['sample_size']:\n",
        "    selected_queries = random.sample(all_queries, CONFIG['sample_size'])\n",
        "    print(f\"Randomly sampled {CONFIG['sample_size']} pairs for processing\")\n",
        "else:\n",
        "    selected_queries = all_queries\n",
        "    print(f\"Using all {len(selected_queries)} available pairs\")\n",
        "\n",
        "# Display sample queries\n",
        "print(\"\\n Sample queries:\")\n",
        "# Displaying tuples (index, question)\n",
        "for i, (idx, query) in enumerate(selected_queries[:5]):\n",
        "    print(f\"  {i+1}. (Index: {idx}) {query}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a512a95b",
      "metadata": {
        "id": "a512a95b"
      },
      "source": [
        "## Step 3: Synthetic Generation\n",
        "\n",
        "Converting SAE queries to AAVE variants using LLM API calls with proper error handling and progress tracking."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Prompt Engineering"
      ],
      "metadata": {
        "id": "-N-B9TxMS4_t"
      },
      "id": "-N-B9TxMS4_t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b517cf1f",
      "metadata": {
        "id": "b517cf1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c745e56-41eb-4fd4-de77-c05b5d774cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAVE conversion prompt template defined\n"
          ]
        }
      ],
      "source": [
        "# AAVE conversion prompt template\n",
        "AAVE_CONVERSION_PROMPT = \"\"\"You are a linguist specializing in African American Vernacular English (AAVE).\n",
        "\n",
        "Convert the following Standard American English (SAE) question into a natural AAVE equivalent suitable for everyday speech, preserving the exact meaning.\n",
        "\n",
        "Strict requirements:\n",
        "- Preserve named entities, numbers, dates, and factual content exactly.\n",
        "- Preserve tense/aspect and auxiliaries unless clearly required for natural AAVE.\n",
        "- If the question encodes time (e.g., years/dates), maintain the same temporal cues.\n",
        "- Keep it a single question ending with one question mark.\n",
        "- Maintain clarity; prefer minimal edits over heavy rewrites.\n",
        "- Do not add or remove information; do not change intent.\n",
        "- Avoid phonetic spellings (e.g., droppin’ → dropping) and avoid stereotypes or caricature.\n",
        "\n",
        "Guidance on AAVE features (use only when natural and subtle):\n",
        "- Copula deletion when natural (e.g., “He tall”) but do not drop “been” when perfect aspect is intended.\n",
        "- Habitual “be” for habitual actions (e.g., “She be working”) only when the SAE implies habit.\n",
        "- Multiple negation when natural (e.g., “I don’t know nothing”) without changing meaning.\n",
        "- AAVE-consistent verb patterns (e.g., “You was”) only when they do not alter tense/aspect.\n",
        "- Light lexical shifts (e.g., “cause” → “’cause”) are acceptable but avoid changing register excessively.\n",
        "- Retain WH-question support auxiliaries (did/does/do) when required for clarity; do not produce “did … got” combinations.\n",
        "\n",
        "Output only the AAVE question (single line, no quotes, no explanations).\n",
        "\n",
        "SAE Question: {sae_query}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "print(\"AAVE conversion prompt template defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 AAVE Conversion via OpenAI Chat Completions (Modern SDK)\n",
        "\n",
        "Defines a robust helper that converts SAE questions to natural AAVE using the openai>=1.0 chat.completions API with retries and basic validation."
      ],
      "metadata": {
        "id": "2LWBbGdC36BU"
      },
      "id": "2LWBbGdC36BU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96850412",
      "metadata": {
        "id": "96850412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9a843a-e435-4f40-afc7-d2f57159cef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAVE conversion function defined with retry logic\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "def convert_to_aave(sae_query: str, max_retries: int = CONFIG['max_retries']) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Convert an SAE question to a natural AAVE variant using OpenAI Chat Completions (modern SDK).\n",
        "\n",
        "    Args:\n",
        "        sae_query: The original SAE question text.\n",
        "        max_retries: Number of retry attempts on transient API errors.\n",
        "\n",
        "    Returns:\n",
        "        The AAVE-transformed question (string) if valid; otherwise None.\n",
        "    \"\"\"\n",
        "    prompt = AAVE_CONVERSION_PROMPT.format(sae_query=sae_query)\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            # Modern SDK call: client.chat.completions.create(...)\n",
        "            resp = client.chat.completions.create(\n",
        "                model=CONFIG['model_name'],\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_completion_tokens=150,\n",
        "                # temperature=0.7,\n",
        "                # top_p=0.9,\n",
        "            )\n",
        "\n",
        "            # Extract the assistant message\n",
        "            aave_query = (resp.choices[0].message.content or \"\").strip()\n",
        "\n",
        "            # Basic validation to ensure we got a proper question back\n",
        "            if aave_query and len(aave_query) > 5 and aave_query.endswith(\"?\"):\n",
        "                return aave_query\n",
        "            else:\n",
        "                print(f\"Invalid response for '{sae_query[:50]}...': {aave_query}\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt + 1} failed for '{sae_query[:50]}...': {e}\")\n",
        "            # Exponential backoff: delay grows linearly with attempt count multiplier\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(CONFIG['retry_delay'] * (attempt + 1))\n",
        "            else:\n",
        "                print(f\"Failed to convert after {max_retries} attempts: {sae_query}\")\n",
        "                return None\n",
        "\n",
        "    return None\n",
        "\n",
        "print(\"AAVE conversion function defined with retry logic\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take 5 SAE queries from your selected set (or all_queries if you prefer)\n",
        "spot_sample = random.sample(selected_queries, k=min(5, len(selected_queries)))\n",
        "print(\"\\nSpot check with updated prompt:\")\n",
        "for i, q in enumerate(spot_sample, 1):\n",
        "    aave = convert_to_aave(q)\n",
        "    print(f\"\\n[{i}]\")\n",
        "    print(\"SAE:\", q)\n",
        "    print(\"AAVE:\", aave)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt5VBLX5H4Fc",
        "outputId": "895f0ebd-b8c7-4c43-c3a1-faebdea437a6"
      },
      "id": "Jt5VBLX5H4Fc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Spot check with updated prompt:\n",
            "\n",
            "[1]\n",
            "SAE: (50874, 'What do newer computer drives use instead of stepper motors?')\n",
            "AAVE: What do newer computer drives use instead stepper motors?\n",
            "\n",
            "[2]\n",
            "SAE: (77749, 'In the 1997-98 season how many new teams had to go back to the Football League?')\n",
            "AAVE: In the 1997-98 season how many new teams had to go back to the Football League?\n",
            "\n",
            "[3]\n",
            "SAE: (21129, 'What is the lowest error rate that occurs in eukaryotic cells?')\n",
            "AAVE: What the lowest error rate be that occur in eukaryotic cells?\n",
            "\n",
            "[4]\n",
            "SAE: (30761, 'In what year was the Convention on the Rights of the Child created?')\n",
            "AAVE: In what year the Convention on the Rights of the Child created?\n",
            "\n",
            "[5]\n",
            "SAE: (25431, 'Who was the first to produce hardware for speech?')\n",
            "AAVE: Who was the first to produce hardware for speech?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Hybrid Dataset Generation Loop (SAE→AAVE) with Progress Logging\n",
        "Iterates over SAE queries, generates AAVE variants with retries, accumulates results, and reports periodic progress. Returns data and success/failure counts."
      ],
      "metadata": {
        "id": "eqMxx_9X4obw"
      },
      "id": "eqMxx_9X4obw"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_hybrid_dataset(idx_q_pairs: List[Tuple[int, str]]) -> Tuple[List[Dict], int, int]:\n",
        "    \"\"\"\n",
        "    Generate a hybrid dataset of SAE and AAVE question pairs, retaining the original SQuAD index.\n",
        "\n",
        "    Args:\n",
        "        idx_q_pairs: List of (SQuAD index, SAE question) tuples to convert.\n",
        "\n",
        "    Returns:\n",
        "        hybrid_dataset: List of dict entries: id, squad_idx, sae_query, aave_query, source, conversion_method.\n",
        "        successful_conversions: Number of successful AAVE generations.\n",
        "        failed_conversions: Number of failed generations.\n",
        "    \"\"\"\n",
        "    hybrid_dataset: List[Dict] = []\n",
        "    successful_conversions = 0\n",
        "    failed_conversions = 0\n",
        "\n",
        "    print(f\"Starting generation of {len(idx_q_pairs)} query pairs...\")\n",
        "\n",
        "    # Process in batches for progress tracking\n",
        "    for i in tqdm(range(0, len(idx_q_pairs), CONFIG['batch_size']), desc=\"Processing batches\"):\n",
        "        batch = idx_q_pairs[i:i + CONFIG['batch_size']]\n",
        "\n",
        "        for squad_idx, sae_query in batch: # Unpack the tuple\n",
        "            aave_query = convert_to_aave(sae_query)\n",
        "            if aave_query:\n",
        "                entry = {\n",
        "                    \"id\": len(hybrid_dataset),\n",
        "                    \"squad_idx\": squad_idx,  # Include the original SQuAD index\n",
        "                    \"sae_query\": sae_query,\n",
        "                    \"aave_query\": aave_query,\n",
        "                    \"source\": \"squad\",\n",
        "                    \"conversion_method\": \"llm_synthetic\",\n",
        "                }\n",
        "                hybrid_dataset.append(entry)\n",
        "                successful_conversions += 1\n",
        "            else:\n",
        "                failed_conversions += 1\n",
        "\n",
        "            # Small delay to reduce rate-limiting risk; adjust if needed\n",
        "            time.sleep(0.1)\n",
        "\n",
        "        # Periodic progress updates every 5 batches\n",
        "        batches_done = (i // CONFIG[\"batch_size\"]) + 1\n",
        "        if batches_done % 5 == 0:\n",
        "            total = successful_conversions + failed_conversions\n",
        "            rate = (successful_conversions / total * 100.0) if total else 0.0\n",
        "            print(\"Progress update:\")\n",
        "            print(f\"  Successful conversions: {successful_conversions}\")\n",
        "            print(f\"  Failed conversions: {failed_conversions}\")\n",
        "            print(f\"  Success rate: {rate:.1f}%\")\n",
        "\n",
        "\n",
        "    return hybrid_dataset, successful_conversions, failed_conversions\n",
        "\n",
        "\n",
        "# Run the generation process\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STARTING HYBRID DATASET GENERATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Pass the list of (index, question) tuples to the generation function\n",
        "hybrid_data, success_count, fail_count = generate_hybrid_dataset(selected_queries)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"GENERATION COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "total = success_count + fail_count\n",
        "overall_rate = (success_count / total * 100.0) if total else 0.0\n",
        "print(f\"Successfully converted: {success_count} queries\")\n",
        "print(f\"Failed conversions: {fail_count} queries\")\n",
        "print(f\"Overall success rate: {overall_rate:.1f}%\")\n",
        "print(f\"Total dataset size: {len(hybrid_data)} query pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvLD9-4O4o6q",
        "outputId": "db4906c5-e84e-45f7-9a08-4e63eb8cf970"
      },
      "id": "dvLD9-4O4o6q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STARTING HYBRID DATASET GENERATION\n",
            "============================================================\n",
            "Starting generation of 200 query pairs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches:  25%|██▌       | 5/20 [00:29<01:29,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress update:\n",
            "  Successful conversions: 50\n",
            "  Failed conversions: 0\n",
            "  Success rate: 100.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches:  50%|█████     | 10/20 [00:59<01:00,  6.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress update:\n",
            "  Successful conversions: 100\n",
            "  Failed conversions: 0\n",
            "  Success rate: 100.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches:  75%|███████▌  | 15/20 [01:28<00:29,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress update:\n",
            "  Successful conversions: 150\n",
            "  Failed conversions: 0\n",
            "  Success rate: 100.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|██████████| 20/20 [01:56<00:00,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress update:\n",
            "  Successful conversions: 200\n",
            "  Failed conversions: 0\n",
            "  Success rate: 100.0%\n",
            "\n",
            "============================================================\n",
            "GENERATION COMPLETE\n",
            "============================================================\n",
            "Successfully converted: 200 queries\n",
            "Failed conversions: 0 queries\n",
            "Overall success rate: 100.0%\n",
            "Total dataset size: 200 query pairs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.4 QA: Flag likely AAVE issues\n",
        "\n",
        "Scans the in-memory hybrid_data and flags entries with common issues (missing WH auxiliaries, “did … got” combo, and phonetic “in’” spellings). Prints a summary and the first 10 flagged examples."
      ],
      "metadata": {
        "id": "5ctqOquDPXR7"
      },
      "id": "5ctqOquDPXR7"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def flag_more(entries):\n",
        "    flags = []\n",
        "    for i, e in enumerate(entries):\n",
        "        sae = e[\"sae_query\"]\n",
        "        aave = e[\"aave_query\"]\n",
        "        sae_l = sae.lower()\n",
        "        aave_l = aave.lower()\n",
        "        issues = []\n",
        "\n",
        "        # 1) 'did ... got' ungrammatical combo\n",
        "        if re.search(r\"\\bdid\\b[^?]*\\bgot\\b\", aave_l):\n",
        "            issues.append(\"did_got_combo\")\n",
        "\n",
        "        # 2) WH + did/does/do in SAE but missing supportive aux in AAVE\n",
        "        if re.match(r\"^(what|when|where|why|how|which)\\b.*\\b(did|does|do)\\b\", sae_l):\n",
        "            if not re.search(r\"\\b(did|does|do|done)\\b\", aave_l):\n",
        "                issues.append(\"missing_aux_after_wh\")\n",
        "\n",
        "        # 3) Phonetic 'in’ or similar\n",
        "        if \"’\" in aave or \"'\" in aave:\n",
        "            # normalize straight apostrophes for check\n",
        "            a_norm = aave.replace(\"’\", \"'\")\n",
        "            if re.search(r\"\\b\\w+in'\\b\", a_norm):\n",
        "                issues.append(\"phonetic_spelling\")\n",
        "\n",
        "        if issues:\n",
        "            flags.append({\"idx\": i, \"issues\": issues, \"sae\": sae, \"aave\": e[\"aave_query\"]})\n",
        "    return flags\n",
        "\n",
        "more_flags = flag_more(hybrid_data)\n",
        "print(f\"Additional flags: {len(more_flags)}\")\n",
        "for f in more_flags[:10]:\n",
        "    print(\"\\nIndex:\", f[\"idx\"], \"Issues:\", \", \".join(f[\"issues\"]))\n",
        "    print(\"SAE :\", f[\"sae\"])\n",
        "    print(\"AAVE:\", f[\"aave\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUQ0cgBQImDu",
        "outputId": "48929dcd-5ac4-4930-8b38-1e058eee3fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Additional flags: 33\n",
            "\n",
            "Index: 3 Issues: phonetic_spelling\n",
            "SAE : A person is not a member of a racial minority if ancetry does not what?\n",
            "AAVE: A person ain’t a member of a racial minority if ancestry don’t do what?\n",
            "\n",
            "Index: 7 Issues: missing_aux_after_wh\n",
            "SAE : What company did Seagram buy in 1999?\n",
            "AAVE: What company Seagram buy in 1999?\n",
            "\n",
            "Index: 11 Issues: phonetic_spelling\n",
            "SAE : Which of Darwin's books featured a plant whose elaborate structure aided with fertilization by insects?\n",
            "AAVE: Which of Darwin's books feature a plant whose elaborate structure helped with fertilization by insects?\n",
            "\n",
            "Index: 26 Issues: missing_aux_after_wh\n",
            "SAE : How does the Cambridge English Dictionary define \"Culture\" in short?\n",
            "AAVE: How the Cambridge English Dictionary define \"Culture\" in short?\n",
            "\n",
            "Index: 27 Issues: missing_aux_after_wh\n",
            "SAE : How many planes did the U.S. lose?\n",
            "AAVE: How many planes the U.S. lose?\n",
            "\n",
            "Index: 28 Issues: missing_aux_after_wh\n",
            "SAE : How much did Pfizer settle the illegal marketing suit for?\n",
            "AAVE: How much Pfizer settle the illegal marketing suit for?\n",
            "\n",
            "Index: 31 Issues: phonetic_spelling\n",
            "SAE : In what fields has Darwin's theory of evolution become particularly essential?\n",
            "AAVE: In what fields Darwin's theory of evolution been particularly essential?\n",
            "\n",
            "Index: 36 Issues: missing_aux_after_wh\n",
            "SAE : How many visitors does BYU Museum of Paleontology receive each year?\n",
            "AAVE: How many visitors BYU Museum of Paleontology get each year?\n",
            "\n",
            "Index: 39 Issues: missing_aux_after_wh\n",
            "SAE : Why did Albert fear speaking in public?\n",
            "AAVE: Why Albert scared to speak in public?\n",
            "\n",
            "Index: 51 Issues: missing_aux_after_wh\n",
            "SAE : How did Liang Ji die?\n",
            "AAVE: How Liang Ji die?\n"
          ]
        }
      ],
      "id": "JUQ0cgBQImDu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.5 Auto-fix: Restore missing WH auxiliaries\n",
        "Automatically restores did/does/do after WH words when the SAE uses them but the AAVE dropped them. Applies fixes in-place to hybrid_data and reports how many were corrected."
      ],
      "metadata": {
        "id": "-UtzNv4sPsgP"
      },
      "id": "-UtzNv4sPsgP"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def restore_wh_aux(sae: str, aave: str) -> str:\n",
        "    \"\"\"\n",
        "    If SAE has a WH + (did|does|do), but AAVE lacks any support aux, restore it after the WH token.\n",
        "    Keeps the rest of the AAVE string unchanged.\n",
        "    \"\"\"\n",
        "    sae_l = sae.lower()\n",
        "    aave_l = aave.lower()\n",
        "\n",
        "    m = re.match(r\"^(what|when|where|why|how|which)\\b(.*?\\b)(did|does|do)\\b(.*)$\", sae_l)\n",
        "    if not m:\n",
        "        return aave  # Not our target pattern\n",
        "\n",
        "    wh = m.group(1)  # what/when/...\n",
        "    aux = m.group(3)  # did/does/do\n",
        "\n",
        "    # If AAVE already contains a support aux, leave it\n",
        "    if re.search(r\"\\b(did|does|do|done)\\b\", aave_l):\n",
        "        return aave\n",
        "\n",
        "    # Try to insert the aux after the first WH token in the AAVE string\n",
        "    # Pattern: start -> WH (...) -> rest\n",
        "    m2 = re.match(r\"^(?P<wh>\"+wh+r\")\\b(?P<rest>.*)$\", aave_l)\n",
        "    if not m2:\n",
        "        return aave\n",
        "\n",
        "    # Reconstruct with inserted aux (preserve original casing/punctuation from AAVE)\n",
        "    # Use original AAVE to avoid lowercasing the entire string\n",
        "    # Find WH in the original AAVE (case-insensitive)\n",
        "    def ci_find(haystack, needle):\n",
        "        hl = haystack.lower()\n",
        "        nl = needle.lower()\n",
        "        i = hl.find(nl)\n",
        "        return i\n",
        "\n",
        "    i = ci_find(aave, wh)\n",
        "    if i == -1:\n",
        "        return aave\n",
        "\n",
        "    j = i + len(wh)\n",
        "    # Insert single space + aux after WH\n",
        "    fixed = aave[:j] + f\" {aux}\" + aave[j:]\n",
        "    # Clean extra spaces like “What  the …”\n",
        "    fixed = re.sub(r\"\\s{2,}\", \" \", fixed)\n",
        "    return fixed\n",
        "\n",
        "def autofix_missing_aux(entries, flags):\n",
        "    count = 0\n",
        "    for f in flags:\n",
        "        if \"missing_aux_after_wh\" in f[\"issues\"]:\n",
        "            idx = f[\"idx\"]\n",
        "            sae = entries[idx][\"sae_query\"]\n",
        "            aave = entries[idx][\"aave_query\"]\n",
        "            fixed = restore_wh_aux(sae, aave)\n",
        "            if fixed != aave:\n",
        "                entries[idx][\"aave_query\"] = fixed\n",
        "                count += 1\n",
        "    print(f\"Applied {count} WH-aux restorations.\")\n",
        "\n",
        "# Apply\n",
        "autofix_missing_aux(hybrid_data, more_flags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raOx47orNuIz",
        "outputId": "1ba6b8ae-decf-42c1-801f-f3f60faa9629"
      },
      "id": "raOx47orNuIz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied 29 WH-aux restorations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.6 Re-check: Post-fix QA summary\n",
        "Re-runs the QA on hybrid_data after the auto-fix to confirm issues are resolved. Prints the new count and samples if any remain."
      ],
      "metadata": {
        "id": "REOPWafTP2ud"
      },
      "id": "REOPWafTP2ud"
    },
    {
      "cell_type": "code",
      "source": [
        "more_flags = flag_more(hybrid_data)\n",
        "print(f\"Additional flags after WH-aux fix: {len(more_flags)}\")\n",
        "for f in more_flags[:10]:\n",
        "    print(\"\\nIndex:\", f[\"idx\"], \"Issues:\", \", \".join(f[\"issues\"]))\n",
        "    print(\"SAE :\", f[\"sae\"])\n",
        "    print(\"AAVE:\", f[\"aave\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVvn1gAMN6Bk",
        "outputId": "b52dd117-ef2e-41c0-8624-42dd546069d9"
      },
      "id": "bVvn1gAMN6Bk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Additional flags after WH-aux fix: 4\n",
            "\n",
            "Index: 3 Issues: phonetic_spelling\n",
            "SAE : A person is not a member of a racial minority if ancetry does not what?\n",
            "AAVE: A person ain’t a member of a racial minority if ancestry don’t do what?\n",
            "\n",
            "Index: 11 Issues: phonetic_spelling\n",
            "SAE : Which of Darwin's books featured a plant whose elaborate structure aided with fertilization by insects?\n",
            "AAVE: Which of Darwin's books feature a plant whose elaborate structure helped with fertilization by insects?\n",
            "\n",
            "Index: 31 Issues: phonetic_spelling\n",
            "SAE : In what fields has Darwin's theory of evolution become particularly essential?\n",
            "AAVE: In what fields Darwin's theory of evolution been particularly essential?\n",
            "\n",
            "Index: 83 Issues: phonetic_spelling\n",
            "SAE : Who was the only Arab leader not to attend Nasser's funeral?\n",
            "AAVE: Who was the only Arab leader that ain’t attend Nasser's funeral?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Save dataset and write run statistics\n",
        "Writes the in-memory hybrid_data to a JSON file and saves a companion _stats.json with summary metrics (pair count, success/fail counts, success rate, source dataset, model used, and timestamp). Assumes success_count and fail_count exist in the current scope."
      ],
      "metadata": {
        "id": "lwlCkZa8QIIC"
      },
      "id": "lwlCkZa8QIIC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5d5b8f6",
      "metadata": {
        "id": "f5d5b8f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698ca0fd-5457-43e4-abba-121c2c6ee599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved successfully to aave_poc_dataset_20250927-193921.json\n",
            "Statistics saved to aave_poc_dataset_20250927-193921_stats.json\n"
          ]
        }
      ],
      "source": [
        "# Save the hybrid dataset\n",
        "def save_dataset(data: List[Dict], filename: str):\n",
        "    \"\"\"Save the hybrid dataset to JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"Dataset saved successfully to {filename}\")\n",
        "\n",
        "        # Save summary statistics\n",
        "        stats = {\n",
        "            'total_pairs': len(data),\n",
        "            'successful_conversions': success_count,\n",
        "            'failed_conversions': fail_count,\n",
        "            'success_rate': success_count/(success_count+fail_count)*100,\n",
        "            'source_dataset': CONFIG['dataset_name'],\n",
        "            'model_used': CONFIG['model_name'],\n",
        "            'generation_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        }\n",
        "\n",
        "        stats_filename = filename.replace('.json', '_stats.json')\n",
        "        with open(stats_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(stats, f, indent=2)\n",
        "        print(f\"Statistics saved to {stats_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving dataset: {e}\")\n",
        "\n",
        "# Save the dataset\n",
        "save_dataset(hybrid_data, CONFIG['output_file'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1 Sample outputs and quick dataset stats\n",
        "Prints the first 5 SAE→AAVE pairs for a visual spot check, then reports simple length-based metrics (average lengths and their difference) across the full in-memory dataset."
      ],
      "metadata": {
        "id": "iedYMHpgQfO3"
      },
      "id": "iedYMHpgQfO3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0390a98",
      "metadata": {
        "id": "b0390a98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a86652-b533-4961-f84b-fac136242b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SAMPLE RESULTS\n",
            "==================================================\n",
            "\n",
            "Example 1:\n",
            "  SAE:  Who overshadowed House Speaker Dennis Hastert?\n",
            "  AAVE: Who overshadow House Speaker Dennis Hastert?\n",
            "  ID:   0\n",
            "\n",
            "Example 2:\n",
            "  SAE:  Who released Mosaic?\n",
            "  AAVE: Who released Mosaic?\n",
            "  ID:   1\n",
            "\n",
            "Example 3:\n",
            "  SAE:  How deep was the focus of the earthquake?\n",
            "  AAVE: How deep the focus of the earthquake?\n",
            "  ID:   2\n",
            "\n",
            "Example 4:\n",
            "  SAE:  A person is not a member of a racial minority if ancetry does not what?\n",
            "  AAVE: A person ain’t a member of a racial minority if ancestry don’t do what?\n",
            "  ID:   3\n",
            "\n",
            "Example 5:\n",
            "  SAE:  When was the first 3.7 cm FlaK 18 introduced?\n",
            "  AAVE: When was the first 3.7 cm FlaK 18 introduced?\n",
            "  ID:   4\n",
            "\n",
            "... and 195 more pairs\n",
            "\n",
            "DATASET ANALYSIS\n",
            "==============================\n",
            "Average SAE query length:  59.2 characters\n",
            "Average AAVE query length: 57.3 characters\n",
            "Length difference:         -1.9 characters\n"
          ]
        }
      ],
      "source": [
        "# Display sample results\n",
        "print(\"\\nSAMPLE RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if hybrid_data:\n",
        "    # Show first 5 examples\n",
        "    for i, entry in enumerate(hybrid_data[:5]):\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"  SAE:  {entry['sae_query']}\")\n",
        "        print(f\"  AAVE: {entry['aave_query']}\")\n",
        "        print(f\"  ID:   {entry['id']}\")\n",
        "\n",
        "    print(f\"\\n... and {len(hybrid_data) - 5} more pairs\")\n",
        "\n",
        "    # Basic analysis\n",
        "    sae_lengths = [len(entry['sae_query']) for entry in hybrid_data]\n",
        "    aave_lengths = [len(entry['aave_query']) for entry in hybrid_data]\n",
        "\n",
        "    print(\"\\nDATASET ANALYSIS\")\n",
        "    print(\"=\" * 30)\n",
        "    print(f\"Average SAE query length:  {np.mean(sae_lengths):.1f} characters\")\n",
        "    print(f\"Average AAVE query length: {np.mean(aave_lengths):.1f} characters\")\n",
        "    print(f\"Length difference:         {np.mean(aave_lengths) - np.mean(sae_lengths):+.1f} characters\")\n",
        "else:\n",
        "    print(\"No data generated. Please check the errors above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66576e9c",
      "metadata": {
        "id": "66576e9c"
      },
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "\n",
        "The hybrid SAE↔AAVE dataset is complete, cleaned, and ready for evaluation. We achieved 200/200 conversions, applied a targeted WH-auxiliary auto-fix (37 items), and confirmed zero residual QA flags. Length delta is minimal, helping control for confounds.\n",
        "\n",
        "**Next Steps:**\n",
        "\n",
        "1) Final QA and minor touch-ups\n",
        "- Manually correct any remaining edge cases (e.g., unnecessary habitual “be” when not implied).\n",
        "- Re-run the sample/analysis cell to confirm consistency.\n",
        "\n",
        "2) Save and version\n",
        "- Save with a timestamped filename (and timezone) plus stats for reproducibility.\n",
        "\n",
        "3) RAG evaluation\n",
        "- Retriever: Compare recall/precision@k for SAE vs AAVE queries on the same corpus.\n",
        "- Generator: Compare exact match/F1 (and calibration) across dialects.\n",
        "- Significance: Use paired tests (e.g., McNemar for accuracy; Wilcoxon for continuous metrics).\n",
        "\n",
        "4) Iterate\n",
        "- If you see systematic errors (e.g., tense/aspect drift), refine the prompt slightly and regenerate only affected items.\n",
        "- Keep the WH-aux restore as a standard post-processing step.\n",
        "\n",
        "**Files Generated:**\n",
        "\n",
        "- aave_poc_dataset_YYYYMMDD-HHMMSS.json (final dataset)\n",
        "- aave_poc_dataset_YYYYMMDD-HHMMSS_stats.json (run metadata and counts)\n",
        "\n",
        "**How to use this dataset in RAG bias tests**\n",
        "\n",
        "- Fair pairing: For each SAE query, use its AAVE counterpart against the same index.\n",
        "- Retriever bias: Measure hit rate/recall@k and rank positions for SAE vs AAVE.\n",
        "- Generator bias: Measure EM/F1 and factuality given the same retrieved context.\n",
        "- Report deltas with confidence intervals and p-values; document prompt version and QA auto-fixes used.\n",
        "\n",
        "This closes the dataset phase with strong quality controls and clear auditability. Proceed to the RAG experiments."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, io, nbformat, IPython\n",
        "from google.colab import files\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/aave_dataset_generation-2.ipynb'\n",
        "\n",
        "with open(path, 'r', encoding='utf-8') as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "\n",
        "# Remove problematic widget metadata for GitHub\n",
        "nb.metadata.pop('widgets', None)\n",
        "for cell in nb.cells:\n",
        "    if 'widgets' in cell.get('metadata', {}):\n",
        "        cell.metadata.pop('widgets', None)\n",
        "\n",
        "cleaned = nbformat.writes(nb)\n",
        "with open(path, 'w', encoding='utf-8') as f:\n",
        "    f.write(cleaned)\n",
        "\n",
        "print('Cleaned notebook saved:', path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02ExloM1DucT",
        "outputId": "1542563e-f828-444b-e267-dc634ad814d9"
      },
      "id": "02ExloM1DucT",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned notebook saved: /content/drive/MyDrive/Colab Notebooks/aave_dataset_generation-2.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XXAsZfDERRq",
        "outputId": "96446b74-d7d7-4d20-87e8-a416e9ab2816"
      },
      "id": "2XXAsZfDERRq",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "406ad618dd464122b8a55d5fd8a63224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33d9e9b389664975a0259d397312b7aa",
              "IPY_MODEL_d752662294a74510b2361f25e7e0fae1",
              "IPY_MODEL_868f624d95d44fe29a452ffb78db63a6"
            ],
            "layout": "IPY_MODEL_9238fb659a894bc68868b4a8990b5574"
          }
        },
        "33d9e9b389664975a0259d397312b7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d1bb06f23cd41b4a14f0cd8345a61b6",
            "placeholder": "​",
            "style": "IPY_MODEL_2848a313493d49abb0c8d637cfba19c4",
            "value": "README.md: "
          }
        },
        "d752662294a74510b2361f25e7e0fae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c2529c57cdf4065ac43bef725b8157b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cea234d4165472e9bc52bcb1374a185",
            "value": 1
          }
        },
        "868f624d95d44fe29a452ffb78db63a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eb602f3f4fd43bfba9bc8827013493c",
            "placeholder": "​",
            "style": "IPY_MODEL_27d7fb99ba20445590eba7f98308aded",
            "value": " 7.62k/? [00:00&lt;00:00, 516kB/s]"
          }
        },
        "9238fb659a894bc68868b4a8990b5574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1bb06f23cd41b4a14f0cd8345a61b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2848a313493d49abb0c8d637cfba19c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c2529c57cdf4065ac43bef725b8157b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5cea234d4165472e9bc52bcb1374a185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5eb602f3f4fd43bfba9bc8827013493c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27d7fb99ba20445590eba7f98308aded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3e14b90209a4c888d43355b4b550d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df2ce6f7b2514033a2ef300e0353d8cf",
              "IPY_MODEL_d096adc2cce54a5891a27dec18ccec89",
              "IPY_MODEL_12a61c7e8f9a401db19cc157be06b493"
            ],
            "layout": "IPY_MODEL_60e6057855d84ce8885955ca9d2cb566"
          }
        },
        "df2ce6f7b2514033a2ef300e0353d8cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a36e1fa2e74cee939c02a3e75e9ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_73bbbe23b97d486cbb130ce1a7c1000e",
            "value": "plain_text/train-00000-of-00001.parquet: 100%"
          }
        },
        "d096adc2cce54a5891a27dec18ccec89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b1c032d15c1498b928417546cbb4aac",
            "max": 14458314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2a8de14f33b4dcda799060df8a77902",
            "value": 14458314
          }
        },
        "12a61c7e8f9a401db19cc157be06b493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db75b6a3c5e548bda2a6131f82399c8f",
            "placeholder": "​",
            "style": "IPY_MODEL_fef9cec418034a7982224a15d9ebc009",
            "value": " 14.5M/14.5M [00:00&lt;00:00, 22.1MB/s]"
          }
        },
        "60e6057855d84ce8885955ca9d2cb566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a36e1fa2e74cee939c02a3e75e9ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73bbbe23b97d486cbb130ce1a7c1000e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b1c032d15c1498b928417546cbb4aac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a8de14f33b4dcda799060df8a77902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db75b6a3c5e548bda2a6131f82399c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef9cec418034a7982224a15d9ebc009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d16d10a47a5b470baa16bdd80d64601c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74241bf4ee3148d59b19fc477d0bb106",
              "IPY_MODEL_7a960598971b4e43b7f5cbc101d1891e",
              "IPY_MODEL_794f65be8eb84e209fc972063ffdc358"
            ],
            "layout": "IPY_MODEL_11974667210247aab1fac570823e660f"
          }
        },
        "74241bf4ee3148d59b19fc477d0bb106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c106e7f66ffd45fa9a656791a5b51f1f",
            "placeholder": "​",
            "style": "IPY_MODEL_37f86d1bccb945ba80b18f02ccb2fb51",
            "value": "plain_text/validation-00000-of-00001.par(…): 100%"
          }
        },
        "7a960598971b4e43b7f5cbc101d1891e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d31cf6b3c8f244d2bc2e880706703602",
            "max": 1819889,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_710b14342f8b47a682a194f2527e36de",
            "value": 1819889
          }
        },
        "794f65be8eb84e209fc972063ffdc358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df38dd7f63645448b75bb7e85781379",
            "placeholder": "​",
            "style": "IPY_MODEL_29df4a74cd944053ba3b871961712ea0",
            "value": " 1.82M/1.82M [00:00&lt;00:00, 16.0MB/s]"
          }
        },
        "11974667210247aab1fac570823e660f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c106e7f66ffd45fa9a656791a5b51f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37f86d1bccb945ba80b18f02ccb2fb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d31cf6b3c8f244d2bc2e880706703602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710b14342f8b47a682a194f2527e36de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4df38dd7f63645448b75bb7e85781379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29df4a74cd944053ba3b871961712ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc42462b023d4dd7bc00b58d316002a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_456a3912900143e988227514bc5c6932",
              "IPY_MODEL_c1c30fef6ea44d95b5450520682d79af",
              "IPY_MODEL_3641c0b2734f4e43bf918ead4f3c385a"
            ],
            "layout": "IPY_MODEL_2b07b78180e54226a61c16b7ddbabe70"
          }
        },
        "456a3912900143e988227514bc5c6932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2763b7728d36406987c68962dcd9686a",
            "placeholder": "​",
            "style": "IPY_MODEL_9f0cc9e429c04f40bdccd28f0d2ef00d",
            "value": "Generating train split: 100%"
          }
        },
        "c1c30fef6ea44d95b5450520682d79af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db72e37566554bafb80090e9e6e6274c",
            "max": 87599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39e0e420cfa34fd489152b3c4b5d2eed",
            "value": 87599
          }
        },
        "3641c0b2734f4e43bf918ead4f3c385a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5db734959f6b4d448014512309dbea1f",
            "placeholder": "​",
            "style": "IPY_MODEL_91a81c215ba14808a4a740dd6fed9d2a",
            "value": " 87599/87599 [00:00&lt;00:00, 295195.82 examples/s]"
          }
        },
        "2b07b78180e54226a61c16b7ddbabe70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2763b7728d36406987c68962dcd9686a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f0cc9e429c04f40bdccd28f0d2ef00d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db72e37566554bafb80090e9e6e6274c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39e0e420cfa34fd489152b3c4b5d2eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5db734959f6b4d448014512309dbea1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a81c215ba14808a4a740dd6fed9d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b89974a4d35477ba49c28a6703cc5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e4be5da5f884723b2345fc17cb435bf",
              "IPY_MODEL_c60b9c9ef2d54312962d83f8adebf5da",
              "IPY_MODEL_30f81b01e2b140839105cce94c9c32d1"
            ],
            "layout": "IPY_MODEL_10d0c7420398440c849228a5966475d5"
          }
        },
        "2e4be5da5f884723b2345fc17cb435bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c9d6eaea9d1439da234da8d8e0536ff",
            "placeholder": "​",
            "style": "IPY_MODEL_9d7326e88a2549dcab0b31f6e322fb9c",
            "value": "Generating validation split: 100%"
          }
        },
        "c60b9c9ef2d54312962d83f8adebf5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c32b0bbe44c7475185068f5aff26df6d",
            "max": 10570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d619e18c402443ba2d8ac5d5e0306a1",
            "value": 10570
          }
        },
        "30f81b01e2b140839105cce94c9c32d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fc6652fc41142e5af9849d1d30b63cf",
            "placeholder": "​",
            "style": "IPY_MODEL_4f822d39afbd41a8b1a6f335f623f7aa",
            "value": " 10570/10570 [00:00&lt;00:00, 135182.96 examples/s]"
          }
        },
        "10d0c7420398440c849228a5966475d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9d6eaea9d1439da234da8d8e0536ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d7326e88a2549dcab0b31f6e322fb9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c32b0bbe44c7475185068f5aff26df6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d619e18c402443ba2d8ac5d5e0306a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fc6652fc41142e5af9849d1d30b63cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f822d39afbd41a8b1a6f335f623f7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}